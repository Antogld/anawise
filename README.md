ğŸ“˜ Anawise â€“ Un Social Network Open Source per la VeritÃ 

Anawise Ã¨ un social network open source progettato per favorire una comunicazione autentica, ironica e rispettosa. Unisce le funzionalitÃ  tipiche di un social come Instagram con un sistema avanzato anti-disinformazione, moderazione automatica, fact-checking e interazioni divertenti contro i contenuti complottisti o tossici.

ğŸš€ Stack Tecnologico

Frontend Web: React + Tailwind CSS

App Mobile: React Native (Expo)

Backend API: Node.js + Express

Database: MongoDB

AI/ML: OpenAI API, ConspEmoLLM-v2, Loki (fact-checking), modelli personalizzati

Deployment: Docker, Vercel (frontend), Railway/Render (backend)

Moderazione: Dashboard admin + API automatizzate

ğŸŒ FunzionalitÃ  Social Core

Creazione di profili utente con bio, foto e link

Caricamento e visualizzazione di:

ğŸ“· Foto

ğŸ¥ Video

ğŸ“ Stati/testi

ğŸ“š Stories (a tempo)

ğŸ¬ Reel (short video)

Azioni social:

â¤ï¸ Like

ğŸ’¬ Commenti

ğŸ‘¤ Follow / Unfollow

ğŸ”” Notifiche

ğŸ§  Moderazione intelligente & Anti-disinformazione

ğŸ” Livello A â€“ Moderazione automatica AI

Analisi di:

Testo nei post/commenti

Immagini, video e link

Classificazione automatica in:

Disinformazione

Hate speech

Spam / contenuti offensivi

Azioni:

Nasconde o rimuove il contenuto

Mostra messaggi ironici sostitutivi

Richiede revisione umana se borderline

ğŸ·ï¸ Livello B â€“ Segnalazione utenti

Gli utenti possono segnalare post/commenti sospetti

Se il numero di flag supera una soglia â†’ il contenuto viene messo in revisione o rimosso automaticamente

ğŸ›¡ï¸ Livello C â€“ Revisione umana

Dashboard admin per i moderatori

Review queue: approva / rimuovi / sblocca

Storico e motivazione degli interventi

ğŸ˜µâ€ğŸ’« Anti-complottismo e risposte ironiche

ğŸ¯ ConspEmoLLM-v2

Modello fine-tuned per:

Rilevare contenuti complottisti, ironici o ridicolizzati

Analizzare frasi mascherate e riformulate

ğŸ§ª Loki â€“ Fact-checking assistito

Scompone un contenuto in "claim"

Cerca fonti online verificabili

Assiste i moderatori nelle decisioni

ğŸ¤– Sistema di risposta automatica ironica

âœ”ï¸ 1. Rilevamento commenti ignoranti o tossici

Classificazione basata su:

Parole chiave ("scie chimiche", "la terra Ã¨ piatta")

AI classifiers (OpenAI Moderation, ConspEmoLLM)

ğŸŒ€ 2. Sostituzione automatica del commento

Nasconde l'originale

Inserisce una risposta del tipo:

"Torna a scuola, poi ricominci a commentare"
"Questo utente ha confuso Facebook con Wikipedia"

ğŸ¤– 3. Generatore AI

Esempio prompt:

const prompt = `Un utente ha commentato: "${text}". Genera una risposta ironica, divertente ma civile.`

Risposta generata via OpenAI/Mistral/Claude.

ğŸ”’ Blocco profili disinformativi

ğŸ§± 1. Flagging automatico

Utenti che postano contenuti ripetutamente classificati come:

Teorie infondate ("i vaccini hanno il 5G")

Complottismo estremo ("non siamo mai andati sulla luna")

â†’ Ottengono un punteggio interno â†’ profilazione

ğŸ§© 2. Interfaccia ironica del profilo bloccato

Il profilo Ã¨ oscurato e mostra:

"Questo utente Ã¨ in pausa studio. Torna quando ha capito che la Terra non Ã¨ piatta."

Tutti i contenuti sono nascosti

Pulsante: "Richiedi revisione"

ğŸ’¡ PerchÃ© Anawise

Rilanciare i social come luoghi di veritÃ  e umorismo sano

Combattere la tossicitÃ  e la disinformazione con intelligenza e ironia

Costruire un progetto comunitario, aperto ma professionale, a cui puoi contribuire

ğŸ“¬ Vuoi contribuire?

Leggi CONTRIBUTING.md e unisciti allo sviluppo di Anawise!

Puoi anche supportarci con:

â­ Una stella su GitHub

ğŸ› Issue o suggerimenti

ğŸ’¬ Diffondere il progetto sui social

Licenza: AGPL v3 â€“ Il codice Ã¨ libero. Il nome Anawiseâ„¢ e il logo sono protetti. Vedi TRADEMARK.md

Made with â¤ï¸ per chi ama i fatti, non le fake.
